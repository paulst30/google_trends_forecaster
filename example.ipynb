{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoJr2bu0SeC69llM1WJKlj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "uwhhWF1DqPx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "darts == 0.32.0\n",
        "pytrends == 4.9.2\n",
        "pandas == 2.2.2\n",
        "numpy == 1.26.4\n",
        "matplotlib == 3.8.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f26dMTwjRzo",
        "outputId": "56b839d7-7498-40e1-b43e-f053c263016e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FIUaoTdSkCGK",
        "outputId": "467e7503-0d88-4fb0-caff-c9a16798f971"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: darts==0.32.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.32.0)\n",
            "Requirement already satisfied: pytrends==4.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.9.2)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: matplotlib==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (0.63)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: nfoursid>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: pmdarima>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.0.4)\n",
            "Requirement already satisfied: pyod>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn<1.6.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: shap>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (0.46.0)\n",
            "Requirement already satisfied: statsforecast>=1.4 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (0.14.4)\n",
            "Requirement already satisfied: tbats>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2024.11.0)\n",
            "Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: pytorch-lightning>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.5.0.post0)\n",
            "Requirement already satisfied: tensorboardX>=2.1 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.6.2.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from darts==0.32.0->-r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pytrends==4.9.2->-r requirements.txt (line 2)) (5.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (3.0.11)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod>=0.9.5->darts==0.32.0->-r requirements.txt (line 1)) (0.60.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (1.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (0.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts==0.32.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts==0.32.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts==0.32.0->-r requirements.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.6.0,>=1.0.1->darts==0.32.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap>=0.40.0->darts==0.32.0->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.40.0->darts==0.32.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: coreforecast>=0.0.12 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (0.0.15)\n",
            "Requirement already satisfied: fugue>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: utilsforecast>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (0.2.10)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->darts==0.32.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.1->darts==0.32.0->-r requirements.txt (line 1)) (4.25.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost>=1.6.0->darts==0.32.0->-r requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (3.11.10)\n",
            "Requirement already satisfied: triad>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (0.2.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod>=0.9.5->darts==0.32.0->-r requirements.txt (line 1)) (0.43.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->darts==0.32.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.32.0->-r requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (17.0.0)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (2.4.16)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.32.0->-r requirements.txt (line 1)) (1.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download trends from Google trends\n"
      ],
      "metadata": {
        "id": "HHv3b3-JiqbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = ['Praktikum']\n",
        "cat = '958'\n",
        "models = [ExponentialSmoothing(),\n",
        "          TBATS()]\n",
        "          #Prophet(yearly_seasonality=True, weekly_seasonality=True,)]"
      ],
      "metadata": {
        "id": "WrL6qLd4R0e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile google_trends.py\n",
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytrends.request import TrendReq\n",
        "import time\n",
        "import datetime\n",
        "from darts import TimeSeries\n",
        "from matplotlib import pyplot as plt\n",
        "from darts.metrics import mape\n",
        "from darts.models import ExponentialSmoothing, TBATS, AutoARIMA, Prophet\n",
        "import argparse\n",
        "\n",
        "# functions\n",
        "\n",
        "# get data from google\n",
        "def get_data(keyword, cat):\n",
        "  run = 0\n",
        "  wait = [2, 4, 6, 8]\n",
        "  pt = TrendReq(hl='de-DE', tz=60)\n",
        "  de_data = None\n",
        "\n",
        "  while de_data is None:\n",
        "    try:\n",
        "      pt.build_payload(keyword, cat=cat, timeframe='today 5-y', geo='DE')\n",
        "      de_data = pt.interest_over_time()\n",
        "      de_data = de_data.drop(columns='isPartial')\n",
        "\n",
        "    except Exception as e:\n",
        "      if run == 4:\n",
        "         break\n",
        "      print('Google is rejecting us...')\n",
        "      print('Retrying in', wait[run], 'seconds...')\n",
        "      time.sleep(wait[run])\n",
        "      run += 1\n",
        "\n",
        "  return de_data\n",
        "\n",
        "\n",
        "# data prep\n",
        "def data_prep(data, keyword, split_date):\n",
        "  data = data.reset_index()\n",
        "  ts_data = TimeSeries.from_dataframe(data, 'date', keyword)\n",
        "  train,val = ts_data.split_after(pd.Timestamp(split_date))\n",
        "  return ts_data , train, val\n",
        "\n",
        "\n",
        "# find best model\n",
        "def model_comparison(data, models, keyword, split_date):\n",
        "\n",
        "  # setup\n",
        "  performances = dict()\n",
        "  best_mape = np.Inf\n",
        "\n",
        "  # compare models\n",
        "  for modelx in models:\n",
        "    model = modelx\n",
        "\n",
        "    hfc_params = {\n",
        "    \"series\": data,\n",
        "    \"start\": pd.Timestamp(split_date),\n",
        "    \"forecast_horizon\": 1,\n",
        "    \"verbose\": True,\n",
        "    }\n",
        "\n",
        "    # expanding window backtest\n",
        "    hist_model = model.historical_forecasts(last_points_only=True, **hfc_params)\n",
        "\n",
        "    #calculate and track metrics\n",
        "    mapex = mape(data, hist_model)\n",
        "    model_name = str(model).split(\"(\")[0]\n",
        "    performances.update({model_name : mapex})\n",
        "\n",
        "  # update best model and extract residuals\n",
        "  if mapex < best_mape:\n",
        "    best_mape = mapex\n",
        "    best_model = model\n",
        "\n",
        "    back_forecast = hist_model.pd_dataframe()\n",
        "    residuals = (data.pd_dataframe() - back_forecast)\n",
        "    residuals = residuals.dropna(subset=[keyword[0]])\n",
        "    print(\"found best model\")\n",
        "  return performances, best_model, residuals\n",
        "\n",
        "\n",
        "# train model on all the data\n",
        "def model_production(data, model):\n",
        "\n",
        "  trained_model = model\n",
        "  trained_model.fit(data)\n",
        "  print(\"successfully trained model\")\n",
        "  #potentially save the model here\n",
        "\n",
        "  return trained_model\n",
        "\n",
        "\n",
        "# predict next 60 weeks\n",
        "def model_prediction(trained_model):\n",
        "\n",
        "  forecast = trained_model.predict(n=60)\n",
        "  forecast = forecast.pd_dataframe()\n",
        "\n",
        "  return forecast\n",
        "\n",
        "# generate output files (csv and graphs)\n",
        "def gen_output(data, forecast, residuals):\n",
        "  output = pd.concat([data, forecast, residuals], axis=1)\n",
        "  output.columns =['series', 'forecast', 'residuals']\n",
        "  output.index.name = 'date'\n",
        "  output['train'] = output['series'] + output['residuals']\n",
        "\n",
        "  # save output as csv\n",
        "  output.to_csv('output.csv', index=True)\n",
        "\n",
        "  # generate graphs\n",
        "  fig, axs = plt.subplots(3, 2, figsize=(15, 20))\n",
        "\n",
        "  # forecast\n",
        "  ax = fig.add_subplot(3, 1, 1)  # Create a new subplot spanning the first row\n",
        "  ax.plot(output['series'], label='Series')\n",
        "  ax.plot(output['forecast'], label='Forecast')\n",
        "  ax.set_title('Forecast')\n",
        "  ax.legend()\n",
        "\n",
        "  # Remove the empty axes (axs[0, 0] and axs[0, 1])\n",
        "  fig.delaxes(axs[0, 0])\n",
        "  fig.delaxes(axs[0, 1])\n",
        "\n",
        "  # training data and training prediction\n",
        "  ax = fig.add_subplot(3, 1, 2)  # Create a new subplot spanning the first row\n",
        "  ax.plot(output['series'], label='Train')\n",
        "  ax.plot(output['train'], label='Prediction')\n",
        "  ax.set_title('Training data and residuals')\n",
        "  ax.legend()\n",
        "\n",
        "  # Remove the empty axes (axs[0, 0] and axs[0, 1])\n",
        "  fig.delaxes(axs[1, 0])\n",
        "  fig.delaxes(axs[1, 1])\n",
        "\n",
        "  #plot residuals\n",
        "  axs[2,0].plot(output['residuals'])\n",
        "  axs[2,0].set_title('Residuals over time')\n",
        "\n",
        "  axs[2,1].hist(output['residuals'])\n",
        "  axs[2,1].set_title('Distribution of residuals')\n",
        "\n",
        "  #save graph\n",
        "  fig.savefig('output.png')\n",
        "\n",
        "\n",
        "#### Main function\n",
        "\n",
        "# main function\n",
        "def main(keyword, cat, models, split_date):\n",
        "    # Step 1: Download data\n",
        "    print('Downloading data...')\n",
        "    data = get_data(keyword, cat)\n",
        "\n",
        "    # Step 2: Data preparation\n",
        "    print('Preparing data...')\n",
        "    ts_data , train, val = data_prep(data, keyword, split_date)\n",
        "\n",
        "    # Step 2: Model comparison\n",
        "    performances, best_model, residuals = model_comparison(data = ts_data, models=models, keyword = keyword, split_date = split_date)\n",
        "\n",
        "    # Step 3: Model production (train the best model)\n",
        "    trained_model = model_production(data=ts_data, model=best_model)\n",
        "\n",
        "    # Step 4: Make predictions\n",
        "    forecast = model_prediction(trained_model=trained_model)\n",
        "\n",
        "    # Step 5: generate output files\n",
        "    gen_output(data, forecast, residuals)\n",
        "\n",
        "## direct script call\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # argument parser\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  # input arguments\n",
        "  parser.add_argument('--keyword', type=str, required=True, help='Keyword for google search')\n",
        "  parser.add_argument('--cat', type=str, required=True, help='Comparison catgory for keyword')\n",
        "  parser.add_argument('--models', default = [ExponentialSmoothing()], help='List of models to compare')\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  keyword = args.keyword\n",
        "  cat = args.cat\n",
        "  models = args.models\n",
        "\n",
        "  # constants\n",
        "  date = datetime.datetime.now() - datetime.timedelta(days=365)\n",
        "  split_date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "  # run script\n",
        "  main(keyword = keyword, cat = cat, models = models, split_date = split_date)\n"
      ],
      "metadata": {
        "id": "AIty27MQMN-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef187652-fb06-4316-84de-6f46f4425a06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting google_trends.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python google_trends.py --keyword ['Praktikum'] --cat '958' --models [ExponentialSmoothing(), TBATS()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXLYf4tiUSJp",
        "outputId": "34817ee3-2dd0-4500-ff27-0157d1aa84a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Downloading data...\n",
            "Google is rejecting us...\n",
            "Retrying in 2 seconds...\n",
            "Google is rejecting us...\n",
            "Retrying in 4 seconds...\n",
            "Google is rejecting us...\n",
            "Retrying in 6 seconds...\n",
            "Google is rejecting us...\n",
            "Retrying in 8 seconds...\n",
            "Preparing data...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/google_trends.py\", line 196, in <module>\n",
            "    main(keyword = keyword, cat = cat, models = models, split_date = split_date)\n",
            "  File \"/content/google_trends.py\", line 160, in main\n",
            "    ts_data , train, val = data_prep(data, keyword, split_date)\n",
            "  File \"/content/google_trends.py\", line 41, in data_prep\n",
            "    data = data.reset_index()\n",
            "AttributeError: 'NoneType' object has no attribute 'reset_index'\n"
          ]
        }
      ]
    }
  ]
}